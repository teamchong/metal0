#!/bin/bash
# One-time setup for all benchmark dependencies
# Run once: ./setup_benchmark.sh
# Then benchmarks will always work

set -e

echo "ğŸ”§ Setting up benchmark environment..."
echo ""

# 1. Install system dependencies
echo "ğŸ“¦ Checking system dependencies..."
if ! command -v hyperfine &> /dev/null; then
    echo "  Installing hyperfine..."
    brew install hyperfine
else
    echo "  âœ… hyperfine already installed"
fi

if ! brew list pcre2 &> /dev/null 2>&1; then
    echo "  Installing pcre2..."
    brew install pcre2
else
    echo "  âœ… pcre2 already installed"
fi

# 2. Install Python packages
echo ""
echo "ğŸ Checking Python packages..."
pip3 install --quiet tiktoken rs-bpe transformers 2>/dev/null || true
echo "  âœ… Python packages ready"

# 3. Build TokenDagger
echo ""
echo "ğŸ”¨ Building TokenDagger..."
TOKENDAGGER_DIR="/Users/steven_chong/downloads/repos/TokenDagger"
if [ -d "$TOKENDAGGER_DIR" ]; then
    cd "$TOKENDAGGER_DIR"

    # Set PCRE2 paths
    export CPLUS_INCLUDE_PATH="/opt/homebrew/opt/pcre2/include:$CPLUS_INCLUDE_PATH"
    export LIBRARY_PATH="/opt/homebrew/opt/pcre2/lib:$LIBRARY_PATH"

    # Build
    make clean > /dev/null 2>&1 || true
    if make > /dev/null 2>&1; then
        echo "  âœ… TokenDagger built successfully"
    else
        echo "  âš ï¸  TokenDagger build failed (will skip in benchmarks)"
    fi

    # Install Python binding
    if python3 setup.py install --user > /dev/null 2>&1; then
        echo "  âœ… TokenDagger Python binding installed"
    else
        echo "  âš ï¸  TokenDagger Python binding failed"
    fi
else
    echo "  âš ï¸  TokenDagger not found at $TOKENDAGGER_DIR"
    echo "     Clone it: git clone <repo> $TOKENDAGGER_DIR"
fi

# 4. Create benchmark environment file
echo ""
echo "ğŸ“ Creating benchmark environment..."
cat > .benchmark_env << 'EOF'
# Auto-generated by setup_benchmark.sh
# Source this file before running benchmarks: source .benchmark_env

# PCRE2 paths for TokenDagger
export CPLUS_INCLUDE_PATH="/opt/homebrew/opt/pcre2/include:$CPLUS_INCLUDE_PATH"
export LIBRARY_PATH="/opt/homebrew/opt/pcre2/lib:$LIBRARY_PATH"
export DYLD_LIBRARY_PATH="/opt/homebrew/opt/pcre2/lib:$DYLD_LIBRARY_PATH"

# Python path for custom builds
export PYTHONPATH="${PYTHONPATH}:/Users/steven_chong/downloads/repos/TokenDagger"

echo "âœ… Benchmark environment loaded"
EOF

echo "  âœ… Created .benchmark_env"

# 5. Update Makefile to auto-source environment
echo ""
echo "ğŸ“ Updating Makefile..."
if ! grep -q "source .benchmark_env" Makefile; then
    # Add auto-source to benchmark targets
    sed -i.bak '/^benchmark-encoding:/a\
	@test -f .benchmark_env && source .benchmark_env || true
' Makefile
    echo "  âœ… Makefile updated to auto-load environment"
fi

# 6. Update bench_encoding.sh to include TokenDagger
echo ""
echo "ğŸ“ Updating bench_encoding.sh to include TokenDagger..."

cat > bench_encoding.sh << 'SHELLEOF'
#!/bin/bash
# Hyperfine benchmark: Encoding (all libraries, realistic data)

set -e

# Auto-load environment if available
test -f .benchmark_env && source .benchmark_env || true

echo "âš¡ Encoding Benchmark: All Libraries (realistic corpus)"
echo "============================================================"
echo "Encoding: 583 diverse texts (200K chars) Ã— 100 iterations"
echo ""

# Generate benchmark data if needed
if [ ! -f benchmark_data.json ]; then
    echo "Generating realistic benchmark data..."
    python3 generate_benchmark_data.py
    echo ""
fi

# Create benchmark scripts
cat > /tmp/bench_rsbpe.py << 'PYEOF'
import time, json
from rs_bpe.bpe import openai
with open('benchmark_data.json') as f:
    texts = json.load(f)['texts']
tokenizer = openai.cl100k_base()
for text in texts[:10]: tokenizer.encode(text)  # Warmup
start = time.time()
for _ in range(100):
    for text in texts: tokenizer.encode(text)
print(f"{int((time.time() - start) * 1000)}ms")
PYEOF

cat > /tmp/bench_tiktoken.py << 'PYEOF'
import time, tiktoken, json
with open('benchmark_data.json') as f:
    texts = json.load(f)['texts']
enc = tiktoken.get_encoding("cl100k_base")
for text in texts[:10]: enc.encode(text)  # Warmup
start = time.time()
for _ in range(100):
    for text in texts: enc.encode(text)
print(f"{int((time.time() - start) * 1000)}ms")
PYEOF

cat > /tmp/bench_tokendagger.py << 'PYEOF'
import time, json
try:
    import tokendagger as tiktoken
    with open('benchmark_data.json') as f:
        texts = json.load(f)['texts']
    enc = tiktoken.Encoding.cl100k_base()
    for text in texts[:10]: enc.encode(text)  # Warmup
    start = time.time()
    for _ in range(100):
        for text in texts: enc.encode(text)
    print(f"{int((time.time() - start) * 1000)}ms")
except ImportError:
    print("999999ms")  # Large number to indicate not available
PYEOF

cat > /tmp/bench_hf.py << 'PYEOF'
import time, json
from transformers import GPT2TokenizerFast
with open('benchmark_data.json') as f:
    texts = json.load(f)['texts']
tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')
for text in texts[:10]: tokenizer.encode(text)  # Warmup
start = time.time()
for _ in range(100):
    for text in texts: tokenizer.encode(text)
print(f"{int((time.time() - start) * 1000)}ms")
PYEOF

# Test which libraries are available
echo "Testing available libraries..."
LIBS=""
if python3 /tmp/bench_rsbpe.py > /dev/null 2>&1; then
    LIBS="$LIBS --command-name 'rs-bpe (Rust)' 'python3 /tmp/bench_rsbpe.py'"
    echo "  âœ… rs-bpe"
else
    echo "  âŒ rs-bpe not available"
fi

if python3 /tmp/bench_tiktoken.py > /dev/null 2>&1; then
    LIBS="$LIBS --command-name 'tiktoken (Rust)' 'python3 /tmp/bench_tiktoken.py'"
    echo "  âœ… tiktoken"
else
    echo "  âŒ tiktoken not available"
fi

TOKENDAGGER_RESULT=$(python3 /tmp/bench_tokendagger.py 2>/dev/null || echo "999999ms")
if [ "$TOKENDAGGER_RESULT" != "999999ms" ]; then
    LIBS="$LIBS --command-name 'TokenDagger (C++)' 'python3 /tmp/bench_tokendagger.py'"
    echo "  âœ… TokenDagger"
else
    echo "  âŒ TokenDagger not available (run setup_benchmark.sh)"
fi

if python3 /tmp/bench_hf.py > /dev/null 2>&1; then
    LIBS="$LIBS --command-name 'HuggingFace (Python)' 'python3 /tmp/bench_hf.py'"
    echo "  âœ… HuggingFace"
else
    echo "  âŒ HuggingFace not available"
fi

echo ""
echo "Running benchmark with $(echo $LIBS | grep -o "command-name" | wc -l | xargs) libraries..."
echo ""

# Run hyperfine with available libraries
eval "hyperfine --warmup 1 --runs 5 --export-markdown bench_encoding_results.md $LIBS"

echo ""
echo "ğŸ“Š Results saved to bench_encoding_results.md"
cat bench_encoding_results.md
SHELLEOF

chmod +x bench_encoding.sh
echo "  âœ… bench_encoding.sh updated"

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "âœ… SETUP COMPLETE!"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "Now you can run benchmarks anytime with:"
echo "  make benchmark-encoding"
echo ""
echo "Or manually:"
echo "  source .benchmark_env"
echo "  ./bench_encoding.sh"
echo ""
echo "Everything is now configured to work automatically!"
